{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: Shift-Jis -*-\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import glob\n",
    "import copy\n",
    "from scipy import linalg, stats\n",
    "import itertools\n",
    "from sympy import *\n",
    "from sklearn import mixture\n",
    "import matplotlib as mpl\n",
    "#mpl.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "plt.switch_backend('pdf')\n",
    "\n",
    "import make_database as md\n",
    "import make_bit_frame as mbf\n",
    "import make_distance_matrix as mdm\n",
    "import generate_controler as gc\n",
    "\n",
    "from __future__ import division\n",
    "from multiprocessing import Pool, Value, Array\n",
    "import multiprocessing as multi\n",
    "from joblib import Parallel, delayed\n",
    "from AIC import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "map(lambda x: max(x, x+1), [i for i in range(0, 8)])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pd.DataFrame(new_vec.T, columns=name_list).to_csv('./SpecificCSVFiles/sim_matrix/data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = glob.glob('./csvFileList/*.csv')\n",
    "gcc = gc.GenerateControler(fileList[:], \"./InputValueDB/母音入力数値一覧.csv\", \"./InputValueDB/子音入力数値一覧.csv\")\n",
    "gcc.mainPreProccess()\n",
    "try:\n",
    "    gcc.sumDataFrame(types=0) #結合方法 0ならarticulation\n",
    "    dist = gcc.getSumDistanceMatrix(0)\n",
    "except Exception as e:\n",
    "    print(\"ERROR\")\n",
    "#dist.to_csv('./SpecificCSVFiles/distance.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_max(x, axis=None):\n",
    "    min = x.min(axis=axis, keepdims=True)\n",
    "    max = x.max(axis=axis, keepdims=True)\n",
    "    result = (x-min)/(max-min)\n",
    "    return result\n",
    "\n",
    "def zscore(x, axis = None):\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore\n",
    "\n",
    "def euclidian_(def_vec):\n",
    "    return sqrt(sum(map(lambda i: i**2, def_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ整形\n",
    "origin_vec = map(list, gcc.bit_frame_list)\n",
    "origin_vec = map(np.array, origin_vec)\n",
    "\n",
    "#地点削減\n",
    "#remove_index = [1,3,5, 7, 9, 11, 13, 14, 16, 17, 23, 27, 29, 36, 38, 41, 45, 46, 48, 53, 55, 57, 60, 61, 63, 65, 72, 74, 76, 78, 80, 82, 84, 86, 87, 89, 90, 94]\n",
    "#remove_index = [2,3,4,5,7, 8,9,10, 12, 13, 15, 16, 17, 21, 22, 24, 26, 27, 29,30, 31, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 67,68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85,88, 89, 91, 92, 94]\n",
    "remove_index = [2,3,4,5,7, 8,9,10, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 26, 27, 29,30, 31, 32, 33,34,  35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49,50,  51, 53, 54, 55, 56, 57,58, 59, 60, 61, 62, 63, 64,65, 67,68, 69,70, 71, 72, 73, 75, 76, 77, 78, 79, 80,82, 83, 84, 85,86,88, 89, 91, 92, 94]\n",
    "use_index = np.asarray([0,1,6,11,18,20,25,28])\n",
    "#remove_index = np.delete(np.asarray([i for i in range(0,96)]), use_index)\n",
    "#中南部\n",
    "middle = set(np.array([i for i in range(33, 74)]))\n",
    "#北部\n",
    "north = set(np.array([i for i in range(20,32)]))\n",
    "north = north - set([24, 26, 28, 29, 31])\n",
    "#石垣\n",
    "ishigaki = set(np.array([i for i in range(82,94)]))\n",
    "ishigaki = ishigaki - set([82, 83, 84, 85])\n",
    "#ishigaki = set(np.array([i for i in range(86,96)]))\n",
    "\n",
    "#north.update(ishigaki)\n",
    "all_area = set(np.array([k for k in range(0, 96)]))\n",
    "remove_index = np.array(list(all_area - ishigaki))\n",
    "\n",
    "nv = copy.deepcopy(origin_vec)\n",
    "nv = np.delete(nv, remove_index, 0)\n",
    "name_list = np.delete(gcc.s_name_list, remove_index, 0)\n",
    "new_vec = np.array(nv)\n",
    "print(\"地点削減終了\")\n",
    "\n",
    "new_vec = del_n_index(copy.deepcopy(new_vec))\n",
    "new_vec = np.array(convert2float(new_vec))\n",
    "print(\"データ整形終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_vec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(name_list)):\n",
    "    print(name_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_exps_item(i, p, vector_):\n",
    "    #i番目のデータを削除したデータの生成\n",
    "    i_loss_vector = map(lambda x: np.delete(x, i), copy.deepcopy(vector_)) \n",
    "    #分散共分散行列生成\n",
    "    cm = covaliance_matrix(i_loss_vector)\n",
    "    #分散共分散行列の逆行列生成\n",
    "    inverse_cov_matrix = inverse_matrix(cm)\n",
    "    #平均ベクトル生成\n",
    "    means_vec = map(mean_vec, i_loss_vector)\n",
    "    #i番目のデータベクトル\n",
    "    y = [vector_[x][i] for x in range(len(vector_))]\n",
    "    #平均との差ベクトル\n",
    "    dis_v = np.array(map(float, y)) - np.array(map(float, means_vec))   \n",
    "    sum_of_exps = np.dot(np.dot(dis_v, covaliance_inverse_matrix), dis_v)\n",
    "    if i%500==0: print(\"{0}番目データクロスバリデーション情報基準AICc終了\".format(i))\n",
    "    return sum_of_exps\n",
    "\"\"\"\n",
    "\n",
    "def get_exps_item(i, vector_, means_vec, inverse_cov_matrix):\n",
    "    #i番目のデータベクトル\n",
    "    y = [vector_[x][i] for x in range(len(vector_))]\n",
    "    #平均との差ベクトル\n",
    "    dis_v = np.array(map(float, y)) - np.array(map(float, means_vec))\n",
    "    return np.dot(np.dot(dis_v, inverse_cov_matrix), dis_v)\n",
    "\n",
    "def exps(new_vec, cov_matrix):\n",
    "    n = len(new_vec[0])\n",
    "    vector_ = copy.deepcopy(new_vec)\n",
    "    #平均ベクトル生成\n",
    "    means_vec = map(mean_vec, vector_)\n",
    "    #分散共分散行列の逆行列生成\n",
    "    inverse_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "    n_list = [i for i in range(n)]\n",
    "    sum_of_exps = map(lambda x: get_exps_item(x, vector_, means_vec, inverse_cov_matrix), n_list) #エラーを出力しようとするとdecode error吐く    \n",
    "    return sum(sum_of_exps)\n",
    "\n",
    "def AIC_c(new_vec, cov_matrix, p):\n",
    "    n = len(new_vec[0])\n",
    "    item1 = (n* p * np.log(2*np.pi))\n",
    "    item2 = n*np.log(np.linalg.det(np.array(cov_matrix)))\n",
    "    #item3 = pow((float(n)/(n-1)), 2)*exps(new_vec, cov_matrix)\n",
    "    item3 = exps(new_vec, cov_matrix)\n",
    "    return item1 +  item2 + item3  + 2*p"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with codecs.open(\"SpecificCSVFiles/sim_matrix/estimated_cov_matrix0_1114_identity.csv\", \"r\", \"UTF-8\", \"ignore\") as filer:\n",
    "    init = pd.read_table(filer, delimiter=\",\")\n",
    "    \n",
    "init = init.drop(u\"Unnamed: 0\", axis=1)\n",
    "init = np.asarray(init)\n",
    "#AIC_c(new_vec, init, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partial_corr(C):\n",
    "    C = np.asarray(C)\n",
    "    p = C.shape[1]\n",
    "    P_corr = np.zeros((p, p), dtype=np.float)\n",
    "    for i in range(p):\n",
    "        P_corr[i, i] = 1\n",
    "        for j in range(i+1, p):\n",
    "            idx = np.ones(p, dtype=np.bool)\n",
    "            idx[i] = False\n",
    "            idx[j] = False\n",
    "            beta_i = linalg.lstsq(C[:, idx], C[:, j])[0]\n",
    "            beta_j = linalg.lstsq(C[:, idx], C[:, i])[0]\n",
    "\n",
    "            res_j = C[:, j] - C[:, idx].dot( beta_i)\n",
    "            res_i = C[:, i] - C[:, idx].dot(beta_j)\n",
    "            \n",
    "            corr = stats.pearsonr(res_i, res_j)[0]\n",
    "            P_corr[i, j] = corr\n",
    "            P_corr[j, i] = corr\n",
    "        \n",
    "    return P_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = map(lambda x: x.decode(\"utf-8\"), name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max(corr_coeficient_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_coeficient_matrix = np.corrcoef(new_vec.T.transpose())\n",
    "#corr_coeficient_matrix = covaliance_matrix(new_vec)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = corr_coeficient_matrix\n",
    "#scaler = MinMaxScaler()\n",
    "#scaler.fit(data)\n",
    "#scaler = MinMaxScaler(copy=True, feature_range=(0.0, 1.0))\n",
    "corr_coeficient_matrix_ =  min_max(data)#scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr_coeficient_matrix = np.corrcoef(new_vec.T.transpose())\n",
    "#corr_coeficient_matrix = covaliance_matrix(new_vec)\n",
    "#partial_corr_coef_matrix = partial_corr(corr_coeficient_matrix)\n",
    "#pd.DataFrame(corr_coeficient_matrix, name_list, name_list).plot()\n",
    "\n",
    "# 相関行列のヒートマップを描く\n",
    "sns.set(font=[\"IPAexGothic\"])\n",
    "sns.heatmap(corr_coeficient_matrix, annot=True, xticklabels=feature_names, yticklabels=feature_names)\n",
    "plt.show()\n",
    "#plt.savefig(\"/Users/ieuser/Myresearch/shiny_app/figs/experiment_of_corr/max_min/ishigaki/*a/heatmat_of_corr_min_max.pdf\", format = 'pdf')\n",
    "\n",
    "\n",
    "# 偏相関係数行列のヒートマップを表示する\n",
    "#plt.show()\n",
    "#sns.heatmap(partial_corr_coef_matrix, annot=True, xticklabels=feature_names, yticklabels=feature_names)\n",
    "#plt.show()\n",
    "#plt.savefig(\"/Users/ieuser/Myresearch/shiny_app/figs/experiment_of_corr/ishigaki/all/heatmat_of_par_corr.pdf\", format = 'pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #“グラフ描画，ビジュアライゼーション用パッケージ\n",
    "\n",
    "x = symmetrical2array(corr_coeficient_matrix_)\n",
    "sns.distplot(x ,kde=True, rug=False, bins = 20, norm_hist=True) ##ヒストグラム\n",
    "plt.xlabel(\"correlation cofficient\")\n",
    "#plt.xlabel(\"variance and covariance\")\n",
    "plt.ylabel(\"frequency of value\")\n",
    "#plt.show()\n",
    "plt.savefig(\"/Users/ieuser/Myresearch/shiny_app/figs/experiment_of_corr/max_min/ishigaki/*a/distribution_of_cor_min_max.pdf\", format = 'pdf')\n",
    "#plt.savefig(\"/Users/ieuser/Myresearch/shiny_app/figs/experiment_of_corr/hokubu+ishigaki/hokubu+ishigaki_1/_a/distribution_of_cov.pdf\", format = 'pdf')\n",
    "\"\"\"\n",
    "x = symmetrical2array(partial_corr_coef_matrix)\n",
    "sns.distplot(x, kde=True, rug=False, bins=20) ##ヒストグラム\n",
    "plt.xlabel(\"partial correlation cofficient\")\n",
    "plt.ylabel(\"frequency of value\")\n",
    "#plt.show()\n",
    "plt.savefig(\"/Users/ieuser/Myresearch/shiny_app/figs/experiment_of_corr/ishigaki/all/distribution_of_par_corr.pdf\", format = 'pdf')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def general_inverse_matrix(matrix):\n",
    "    # 特異値分解(singular value decomposition)\n",
    "    U, s, V_t = np.linalg.svd(matrix, full_matrices=True)\n",
    "    rank = np.linalg.matrix_rank(np.array(matrix))\n",
    "    downed_rank = len(matrix) - np.linalg.matrix_rank(np.array(matrix))\n",
    "    # step2 sの逆行列のrank落ちした部分を0に変更\n",
    "    for i in range(downed_rank):\n",
    "        s[-(i + 1)] = 0\n",
    "\n",
    "    object_s = np.diag(s[0:rank])\n",
    "    inv_object_s = np.linalg.inv(object_s)\n",
    "    a = np.array([np.append(inv_object_s[x], [0 for x in range(downed_rank)]) for x in range(rank)])\n",
    "    inv_s = a.tolist()\n",
    "    for k in range(downed_rank):\n",
    "        inv_s.append(([0.0 for x in range(len(matrix))]))\n",
    "\n",
    "    # 一般逆行列\n",
    "    return np.dot(np.dot(V_t.T, np.array(inv_s)), U.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# サンプル\n",
    "#標本共分散S\n",
    "#変数ベクトルとその行列を作成\n",
    "\n",
    "#標本分散共分散行列作成\n",
    "#S = [[0.884, 0.780, 0.028], [0.780, 0.876, 0.458], [0.028, 0.458, 1.005]]\n",
    "#new_vec = np.array([[0.573, 0.223, 1.366],[0.190,0.930, 1.042],[1.585, 1.312, 0.578]])\n",
    "#name_list = [\"x\", \"y\", \"z\"]\n",
    "\n",
    "S = covaliance_matrix(copy.deepcopy(new_vec))\n",
    "#c_m = pd.DataFrame(copy.deepcopy(cov_matrix), name_list, name_list)\n",
    "\n",
    "#パラメーター数\n",
    "p = len(list(itertools.combinations(name_list,2)))\n",
    "n = len(new_vec[0])\n",
    "s_num = len(S)\n",
    "print(\"p = {0}, s_num = {1}\".format(p,  s_num))\n",
    "combination = list(itertools.combinations(np.asarray([x for x in range(s_num+1)]), 2))\n",
    "string_list = [(\"b\"+ str(x[0]) + \"_\"+ str(x[1]-1)) for x in combination]\n",
    "variable_beta = map(Symbol, string_list)\n",
    "\n",
    "beta_matrix = [[0 for x in range(s_num)] for y in range(s_num)]\n",
    "init_a = np.asarray([[0 for x in range(s_num)] for k in range(s_num)])\n",
    "count = 0\n",
    "for com in combination:\n",
    "    beta_matrix[com[0]][com[1]-1] = variable_beta[count]\n",
    "    count = count +1   \n",
    "\n",
    "\n",
    "#パラメータβの初期値行列 (n/tr(分散))*単位行列_{n*n}\n",
    "init_sol = np.dot((s_num/np.trace(S)), np.identity(s_num))\n",
    "#別の初期値\n",
    "#init_sol = np.diag(np.diag(general_inverse_matrix(S)))\n",
    "\n",
    "#initial_matrix = init\n",
    "hoge = list(itertools.combinations(np.asarray([x for x in range(s_num)]), 2))\n",
    "\n",
    "#for i in range(1, 2):#len(hoge)):\n",
    "def Covaliance_Instruction_Selection(i, init_sol, variable_beta, S, p, beta_matrix, initial_matrix=0):\n",
    "    if i != 0:\n",
    "        partial_correlation_matrix = np.linalg.inv(initial_matrix)\n",
    "        partial_correlation_matrix[np.diag_indices_from(partial_correlation_matrix)] = 0\n",
    "        partial_correlation_matrix = pd.DataFrame(copy.deepcopy(partial_correlation_matrix), name_list, name_list)        \n",
    "\n",
    "    sparse_list = []\n",
    "    for k in range(i):\n",
    "        a, b = find_min(np.array(partial_correlation_matrix))\n",
    "        sparse_list.append((a, b))\n",
    "        partial_correlation_matrix.iloc[a][b] = partial_correlation_matrix.iloc[b][a] = 0\n",
    "    \n",
    "    #sparse_listに格納されている絶対値が最小の要素を0にする。\n",
    "    count = 0\n",
    "    for com in combination:\n",
    "        beta_matrix[com[0]][com[1]-1] = variable_beta[count]\n",
    "        count = count +1\n",
    "        \n",
    "    beta_matrix = sparse_matrix(sparse_list, np.array(beta_matrix), init_a) #疎な変数行列   \n",
    "    \n",
    "    #初期f(Sβ)行列\n",
    "    init_beta = np.asarray([flatten([ solve(beta_matrix[x][y] - init_sol[x][y]) if solve(beta_matrix[x][y] - init_sol[x][y]) != [] else 0 for x in range(len(beta_matrix))]) for y in range(len(beta_matrix))])\n",
    "    beta = init_beta\n",
    "    \n",
    "    dv_and_ecm = main(beta, variable_beta, S, init_sol, sparse_list)    \n",
    "    estimated_cov_matrix = dv_and_ecm[2]\n",
    "\n",
    "\n",
    "    ecm = pd.DataFrame(estimated_cov_matrix, name_list, name_list)\n",
    "    ecm.to_csv('./SpecificCSVFiles/estimated_cov_matrix/ishigaki/_a/estimated_cov_matrix_' + str(i) + '.csv', sep=',')   \n",
    "    eicm = pd.DataFrame(np.linalg.inv(estimated_cov_matrix), name_list, name_list)\n",
    "    eicm.to_csv('./SpecificCSVFiles/estimated_cov_matrix/ishigaki/_a/estimated_inverse_cov_matrix_' + str(i) + '.csv', sep=',')\n",
    "    \n",
    "    if i == 0: \n",
    "        initial_matrix = estimated_cov_matrix\n",
    "        oldAIC = AIC_c(new_vec, np.array(estimated_cov_matrix), p)\n",
    "        newAIC=oldAIC\n",
    "    else:\n",
    "        newAIC = AIC_c(new_vec, np.array(estimated_cov_matrix), p-i)\n",
    "    print(\"{0}辺削除モデル、final_delta_value ~ {1}、fina_delta_value_euq ~ {2}, new AIC is ~ {3}\".format(i, dv_and_ecm[0], dv_and_ecm[1], newAIC))\n",
    "    \"\"\"\n",
    "    if oldAIC >= newAIC :\n",
    "        oldAIC = newAIC\n",
    "    else:\n",
    "        break\n",
    "    \"\"\"\n",
    "\n",
    "Covaliance_Instruction_Selection(0, init_sol, variable_beta, S, p, beta_matrix)\n",
    "\n",
    "\"\"\"\n",
    "with codecs.open(\"SpecificCSVFiles/estimated_cov_matrix_18area_ま/estimated_cov_matrix_18area_ま_0.csv\", \"r\", \"UTF-8\", \"ignore\") as filer:\n",
    "    init = pd.read_table(filer, delimiter=\",\")\n",
    "    \n",
    "init = init.drop(u\"Unnamed: 0\", axis=1)\n",
    "init = np.asarray(init)\n",
    "initial_matrix = init\n",
    "\n",
    "unko = Parallel(n_jobs=4)([delayed(Covaliance_Instruction_Selection)(i, init_sol, variable_beta, S, p, beta_matrix, initial_matrix) for i in range(17, len(hoge)+1)])#len(hoge)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"/Users/ieuser/Desktop/Readme.txt\", \"r\", \"UTF-8\", \"ignore\") as filer:\n",
    "    init = pd.read_table(filer, delimiter=\"~ \", header=None)\n",
    "AIC_nums = np.array(init[3])\n",
    "Convergence_value = map(lambda x: float(x.split(u\",\")[0])*5, init[1])\n",
    "#map(lambda x: float(x.split(u\",\")[0]), init[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('pdf')\n",
    "#left = np.array([k for k in range(len(AIC_nums))])\n",
    "left = np.array([1, 2, 3, 4, 8])\n",
    "#height1 = AIC_nums\n",
    "#height2 = Convergence_value\n",
    "height1 = [22.324244,12.258095, 10.689750, 10.090841, 8.032232]\n",
    "height2 = [22.324244, 13.328339, 15.009439,11.441677,12.081639]\n",
    "height3 = [22.324244, 13.336375, 12.966426, 11.779494,13.182462]\n",
    "p1 = plt.plot(left, height1, label = \"openmp\", linewidth=2)\n",
    "p2 = plt.plot(left, height2, label=\"pthread\", linewidth=2, linestyle=\"dashed\")\n",
    "p3 = plt.plot(left, height3, label=\"boost thread\", linewidth=2, linestyle=\"dashed\")\n",
    "plt.legend((p1[0], p2[0], p3[0]), (\"OpenMP\", \"pthread\", \"boost thread\"), loc=2)\n",
    "\n",
    "plt.legend(loc=1)\n",
    "filename = \"hoge.pdf\"\n",
    "plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_valiable_matrix(a, b, valiable, length):\n",
    "    matrix  = [[0 for x in range(length)] for y in range(length)]\n",
    "    matrix[a][b] = valiable\n",
    "    #matrix[b][a] = valiable\n",
    "    return np.array(matrix)\n",
    "\n",
    "def get_det(matrix):\n",
    "    \"\"\"与えられたmatrixの行列式を返す\"\"\"\n",
    "    try:\n",
    "        return np.linalg.det(matrix)\n",
    "    except Exception as e:\n",
    "        #おそらく対角行列の場合は対角要素の積が返される\n",
    "        return reduce(lambda x,y:x*y,np.diag(matrix))\n",
    "\n",
    "def A_k(x, graph):\n",
    "    ak = copy.deepcopy(graph)\n",
    "    ak[x][x] =1\n",
    "    return np.array(ak)\n",
    "\n",
    "def Ai_dot_Bi(x, y, valiables, init_A):\n",
    "    uptri_matrix = np.dot(A_k(x, copy.deepcopy(init_A)),  generate_valiable_matrix(x, y, valiables[x][y], len(valiables)))\n",
    "    downtri_matrix = np.dot(A_k(y, copy.deepcopy(init_A)),  generate_valiable_matrix(y, x, valiables[x][y], len(valiables)))\n",
    "    return np.array(uptri_matrix + downtri_matrix)\n",
    "\n",
    "def sparse_matrix(sparse, valiables, init_A):\n",
    "    Abeta = np.asarray([[0 for i in range(len(valiables))] for k in range(len(valiables))])\n",
    "    comb_list = list(itertools.combinations(np.asarray([x for x in range(len(valiables)+1)]), 2))\n",
    "    using_tapples = filter(lambda x: ((x[0], x[1]-1) not in sparse) and ((x[1]-1, x[0]) not in sparse), comb_list)\n",
    "    abeta = map(lambda x: Ai_dot_Bi(x[0], x[1]-1, valiables, copy.deepcopy(init_A)), using_tapples)\n",
    "    return np.array(sum(abeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 一階微分\n",
    "def onetime_derivative(a, b, S, candidate_cov, sparse_list):\n",
    "    if ((a, b)) in map(set, sparse_list): return 0\n",
    "    init_A = np.asarray([[0 for x in range(len(S))] for k in range(len(S))])\n",
    "    matrix_of_all1 = [[1 for k in range(len(S))] for n in range(len(S))]\n",
    "    Ai = Ai_dot_Bi(a, b, matrix_of_all1, copy.deepcopy(init_A))    \n",
    "    return np.trace(np.dot(S, Ai)) - np.trace(np.dot(candidate_cov, Ai))\n",
    "\n",
    "def twotime_derivative(a, b, c,d, candidate_cov, sparse_list):\n",
    "    if set((a, b)) in map(set, sparse_list) or set((c, d)) in map(set, sparse_list): return 0\n",
    "    init_A = np.asarray([[0 for x in range(len(candidate_cov))] for k in range(len(candidate_cov))])\n",
    "    matrix_of_all1 = [[1 for k in range(len(candidate_cov))] for n in range(len(candidate_cov))]\n",
    "    ai = Ai_dot_Bi(a, b, matrix_of_all1, copy.deepcopy(init_A))\n",
    "    aj = Ai_dot_Bi(c, d, matrix_of_all1, copy.deepcopy(init_A))    \n",
    "    cab = np.dot(candidate_cov, ai)\n",
    "    ccd = np.dot(candidate_cov, aj)\n",
    "    return np.trace(np.dot(cab, ccd))\n",
    "\n",
    "def grade_vector(candidate_cov, S, valiables, sparse_list):\n",
    "    #勾配ベクトル作成 for ニュートン法  S：標本共分散行列\n",
    "    grade_vec = [0 for k in range(len(valiables))]\n",
    "    combination_num = list(itertools.combinations(np.asarray([x for x in range(len(candidate_cov)+1)]), 2))\n",
    "    grade_vec = map(lambda x: onetime_derivative(x[0], x[1]-1, S, candidate_cov, sparse_list), combination_num)\n",
    "    return grade_vec\n",
    "        \n",
    "def hessian_matrix(candidate_cov, valiables, sparse_list):    \n",
    "    #ヘッセ行列作成 for ニュートン法    \n",
    "    hess_matrix = [[0.0 for k in range(len(valiables))] for i in range(len(valiables))]\n",
    "    valiables_comb = list(itertools.combinations(np.asarray([x for x in range(len(valiables)+1)]), 2))\n",
    "    local_comb = list(itertools.combinations(np.asarray([x for x in range(len(candidate_cov)+1)]), 2))\n",
    "    hess_array = np.array(map( lambda x: hessian_task(x[0], x[1], local_comb, candidate_cov, sparse_list), valiables_comb))\n",
    "    for ha in hess_array:\n",
    "        hess_matrix[int(ha[0])][int(ha[1])] = ha[2]\n",
    "    #hess_matrices = map(lambda ha: assign_at_matrix(int(ha[0]), int(ha[1]), ha[2], hess_matrix) , hess_array)\n",
    "    return np.array(hess_matrix)\n",
    "    \n",
    "def hessian_task(x, y, combination, candidate_cov, sparse_list):\n",
    "    #if x==y-1: print(x)\n",
    "    comb_x = combination[x] #目的\n",
    "    comb_y = combination[y-1] #比較対象  \n",
    "    return (int(x), int(y-1), twotime_derivative(comb_x[0], comb_x[1]-1, comb_y[0], comb_y[1]-1, candidate_cov, sparse_list))\n",
    "\n",
    "def assign_at_matrix(x, y, value, matrix):\n",
    "    matrix[x][y] = value\n",
    "    return (matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#0より大きい絶対値最小値探索\n",
    "#\n",
    "def find_min(matrix):\n",
    "    \"\"\"\n",
    "    matrixから最小値をもつカラム番号とインデックス番号を返す\n",
    "    \"\"\"\n",
    "    sorted_matrix = sorted(matrix.reshape(-1,), key=abs)\n",
    "    min_value = sorted_matrix[np.nonzero(sorted_matrix)[0][0]]\n",
    "\n",
    "    #print(\"Min value is {0}\".format(min_value))\n",
    "    for x in range(len(matrix)):\n",
    "        try:\n",
    "            col_num = (matrix[x] == min_value).tolist().index(True)\n",
    "            index_num = x\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    #print(\"絶対値が最小値をもつ組み合わせ：index {0}, columns {1}\".format(index_num, col_num)) \n",
    "    return tuple([index_num, col_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ニュートン法\n",
    "def main(beta, variables_beta, S, initial_solution, sparse_list):\n",
    "    inv_covariance = initial_solution\n",
    "    delta_values = []\n",
    "    delta_values_euq = []\n",
    "    for i in range(10**3):        \n",
    "        try:        \n",
    "            candi_cov = np.linalg.inv(inv_covariance)\n",
    "        except Exception as e:\n",
    "            candi_cov =  np.diag(np.diag(inv_covariance)**-1) #対角行列の逆行列は対角成分の逆数を並べた対角行列である。S^-1 -> S\n",
    "        \"\"\"\n",
    "        if i != 0:\n",
    "            yk = symmetrical2array(new_beta) - symmetrical2array(beta)\n",
    "            new_grade_vec = grade_vector(candi_cov, S, variables_beta, sparse_list) \n",
    "            sk = new_grade_vec - grade_vec\n",
    "            \n",
    "            unit1_1 =  np.identity(len(variables_beta)) - (np.dot(yk, sk.T)/np.dot(yk.T, sk))\n",
    "\n",
    "            unit1_2 = np.identity(len(variables_beta)) - (np.dot(sk, yk.T)/np.dot(yk.T, sk))\n",
    "\n",
    "            unit1 = np.dot(np.dot(unit1_1, approx_hess), unit1_2)\n",
    "\n",
    "            unit2 = (np.dot(yk, yk.T), sk.T)/(np.dot(yk.T, sk))\n",
    "\n",
    "            approx_hess = unit2\n",
    "\n",
    "            beta = new_beta\n",
    "            grade_vec = new_grade_vec\n",
    "        else:\n",
    "        \"\"\"\n",
    "        #勾配ベクトル\n",
    "        grade_vec = grade_vector(candi_cov, S, variables_beta, sparse_list) \n",
    "        \n",
    "        #ヘッセ行列\n",
    "        hess_mat = hessian_matrix(candi_cov, variables_beta, sparse_list) \n",
    "        upper_index = np.triu_indices_from(hess_mat, 0)\n",
    "        hess_mat = array2symmetrical(hess_mat[upper_index], len(hess_mat))                \n",
    "        \n",
    "        try:\n",
    "            inv_hess_mat = np.linalg.inv(hess_mat)            \n",
    "        except Exception as e:\n",
    "            #inv_hess_mat = np.diag([k**-1 if k!=0 else 0 for k in np.diag(hess_mat)])\n",
    "            inv_hess_mat = general_inverse_matrix(hess_mat)\n",
    "        \n",
    "        delta_beta = - np.dot(inv_hess_mat, grade_vec)\n",
    "        #delta_beta = - np.dot(approx_hess, grade_vec)\n",
    "        \n",
    "        delta_value = - np.dot(np.array(grade_vec), delta_beta)  \n",
    "        \n",
    "        array_beta = symmetrical2array(beta)        \n",
    "        \n",
    "        new_beta = Get_SuitableT(array_beta, delta_beta, S, inv_covariance, sparse_list, grade_vec, delta_value)        \n",
    "        #new_beta = Get_SuitableT2(array_beta, delta_beta, S, inv_covariance, sparse_list,  grade_vec)        \n",
    "        if type(new_beta) == int:\n",
    "            #print(\"inv_hessian_mat = {0}, grade_vec = {1}\".format(inv_hess_mat, grade_vec))\n",
    "            break                                                \n",
    "                \n",
    "        init_A = np.asarray([[0 for x in range(len(beta))] for k in range(len(beta))])\n",
    "        new_inv_covariance = sparse_matrix([(None, None)], new_beta, init_A)   \n",
    "        \n",
    "        #delta_value = - np.dot(np.array(grade_vec), delta_beta)  \n",
    "        #delta_value = -(object_function_beta(new_beta, new_inv_covariance, S) - object_function_beta(beta, inv_covariance, S))\n",
    "        delta_value_euq = euclidian_(symmetrical2array(new_beta) - array_beta)\n",
    "        delta_values.append(delta_value)\n",
    "        delta_values_euq.append(delta_value_euq)        \n",
    "        print(\"delta_value ~ {0}, delta_value_euq ~ {1}\".format(delta_value, delta_value_euq)) \n",
    "        \n",
    "        inv_covariance = new_inv_covariance\n",
    "        beta = new_beta\n",
    "        \n",
    "        if delta_value <= 10**(-10): break   \n",
    "                \n",
    "    return(delta_value, delta_value_euq, np.linalg.inv(inv_covariance))   \n",
    "\n",
    "def array2symmetrical(array, matrix_length):\n",
    "    new = np.zeros((matrix_length, matrix_length))\n",
    "    indexs = np.triu_indices_from(new)\n",
    "    new[indexs] = array\n",
    "    new[(indexs[1], indexs[0])] = array\n",
    "    return new\n",
    "\n",
    "def symmetrical2array(matrix):\n",
    "    iu1 = np.triu_indices(len(matrix))\n",
    "    return np.array(matrix[iu1])\n",
    "\n",
    "def object_function_beta(beta_matrix, inv_cov, S):\n",
    "    cm = list(itertools.combinations(np.asarray([x for x in range(len(beta_matrix)+1)]), 2))\n",
    "    try:\n",
    "        product_beta = np.linalg.det(inv_cov)\n",
    "    except Exception as e:\n",
    "        product_beta = np.diag(inv_cov).prod()\n",
    "    return (2 * sum(map(lambda x: beta_matrix[x[0]][x[1]-1]*S[x[0]][x[1]-1] , cm)) - np.log(product_beta))\n",
    "\n",
    "def Get_SuitableT(beta_vec, delta_beta, S, inv_cov, sparse_ls, grade_vec, delta_value):\n",
    "    #beta_vec is original Beta array, S is 精度行列\n",
    "\n",
    "    init_A = np.asarray([[0 for x in range(len(inv_cov))] for k in range(len(inv_cov))])\n",
    "    beta_matrix = array2symmetrical(beta_vec, len(S))\n",
    "    original_object_value = object_function_beta(beta_matrix, inv_cov, S)\n",
    "\n",
    "    if delta_value >= 16:\n",
    "        t = 3\n",
    "    else:\n",
    "        t = 0\n",
    "    while 1:\n",
    "        #new beta array\n",
    "        new_beta_vec = (beta_vec + (2**(-t))*delta_beta)    \n",
    "        \n",
    "        #armijo基準\n",
    "        #new_beta_vec = (beta_vec + alpha*delta_beta)        \n",
    "        \n",
    "        #new beta matrix、 実質 new 精度行列\n",
    "        new_beta_matrix = array2symmetrical(new_beta_vec, len(S))       \n",
    "            \n",
    "        inv_cov = sparse_matrix([(None, None)], new_beta_matrix, init_A) #S^-1\n",
    "\n",
    "        #new beta の元でのf(new_beta)\n",
    "        new_object_value = object_function_beta(new_beta_matrix, inv_cov, S)       \n",
    "\n",
    "        if  original_object_value > new_object_value:\n",
    "            #print(\"t = {0}\".format(t))\n",
    "            return new_beta_matrix            \n",
    "\n",
    "        t += 1\n",
    "        if t >10**3: return 1\n",
    "        \n",
    "def Get_SuitableT2(beta_vec, delta_beta, S, inv_cov, sparse_ls, grade_vec):\n",
    "    #beta_vec is original Beta array, S is 精度行列\n",
    "    init_A = np.asarray([[0 for x in range(len(inv_cov))] for k in range(len(inv_cov))])\n",
    "    beta_matrix = array2symmetrical(beta_vec, len(S))\n",
    "    original_object_value = object_function_beta(beta_matrix, inv_cov, S)   \n",
    "    \n",
    "    alpha = 1.0\n",
    "    depsilon = 10**(-1)\n",
    "    mu = 0.9\n",
    "    while 1:        \n",
    "        new_beta_vec = (beta_vec + alpha*delta_beta)        \n",
    "        \n",
    "        new_beta_matrix = array2symmetrical(new_beta_vec, len(S))       \n",
    "            \n",
    "        inv_cov = sparse_matrix([(None, None)], new_beta_matrix, init_A) #S^-1\n",
    "        \n",
    "        new_grade_vec = grade_vector(np.linalg.inv(inv_cov), S, new_beta_vec, sparse_ls)\n",
    "            \n",
    "        try:  \n",
    "            #new beta の元でのf(new_beta)\n",
    "            new_object_value = object_function_beta(new_beta_matrix, inv_cov, S)   \n",
    "            #wolfe基準とarmijo基準\n",
    "            if np.dot(new_grade_vec.T, delta_beta) >= mu*np.dot(grade_vec.T, delta_beta) and new_object_value <= original_object_value + depsilon*alpha*np.dot(grade_vec.T, delta_beta):\n",
    "                #print(\"alpha = {0}\".format(alpha))\n",
    "                #print(\"new_object_value ~ {0}, origin ~ {1}\".format(new_object_value, original_object_value))\n",
    "                return new_beta_matrix          \n",
    "        except Exception as e:\n",
    "            None\n",
    "        alpha = alpha*(1.25**(-1))\n",
    "        if alpha <= 10**(-15): \n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
